在之前文章给大家分享后不久，就有位小伙伴跟小编说在用scrapy搭建python爬虫中出现错误了。一开始的时候小编也没有看出哪里有问题，好在经过不断地讨论与测试，最终解决了出错点的问题。有同样出错的小伙伴可要好好看看到底是哪里疏忽了，小编这里先不说出问题点。

问题描述：

安装位置：

环境变量：

解决办法：

文件命名叫 scrapy.py，明显和scrapy自己的包名冲突了，这里

class StackOverFlowSpider(scrapy.Spider)

会直接找当前文件(scrapy.py)的Spider属性。

说了这么多，其实就是文件命名问题，所以总结一下经验教训哦

平时一定不要使用和包名或者build-in 函数相同的命名。

到此这篇关于scrapy在python爬虫中搭建出错的解决方法的文章就介绍到这了,更多相关scrapy在python爬虫中搭建出错怎么办内容请搜索脚本之家以前的文章或继续浏览下面的相关文章希望大家以后多多支持脚本之家！

