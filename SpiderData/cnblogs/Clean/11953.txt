每一位成功的程序员，背后也许都站着无数的秃头的男人——为其提供各种开发工具&代码库，当然也包括…… 各种玄学bug……


玄学的开端

最近在用Python做一个爬虫项目的时候遇到一个很奇怪的问题，而且还不是每次都会触发，实在是令人费解……

报错信息如下：

把错误信息拿到搜索引擎去查询一番，中文社区上的说法是在请求的body或者headers里有中文数据，

解决方法是：先encode成UTF-8然后再用latin-1编码decode出来。

不过我请求的数据里面没有中文啊！

由此踏上了令人头秃的抓bug之路


看代码

（又臭又长不看，建议跳过看后续）

先看看我提交的数据的格式吧~

这是身份认证相关的（太长只截取一部分）

以下是header部分代码

以下是requests请求代码：

单纯看这代码，应该是完全没啥问题的，事实上我其他的爬虫也都是这样写的，已经稳定运行一年多了，就最近新写的这个爬虫不行… 有时候代码问题就是这么玄学…

刚才说查到网友说先encode再decode的方法，我试着在headers里的Authorization、Blade-Auth、Cookie这三个字段加上：

这样倒是不会报这个UnicodeEncodeError的错误，但是后端服务那边直接报错说没有登录了……

所以这又是啥问题呢？

继续Stack Overflow查一下，有毛子网友说也遇到这个问题，下面有回答让设置环境变量试试，ok，那我也跟着试试看：

然后在Python里打印一下系统编码和locale：

输出结果

哦吼~ 再试试能不能跑… 还是不行，醉了，那就根本不是这个问题。

好吧，我投降了，不想死磕了。在哪里跌倒，就在哪里躺下

所以是什么问题呢？至今还是未解之谜…


后续

心好累，改用C#写爬虫，放弃Python…

说好的“人生苦短，我用Python”呢？怎么变得这么折腾了 TAT…

（PS：我之前做了一个爬虫平台，可以对不同语言实现的爬虫程序进行调度，提供统一的配置中心、统一的数据持久化接口~ 所以每个爬虫用什么语言写区别并不大）

写下这篇文章就当做记录，希望以后的某一天，这个问题能得到解决~ （美好的愿望）


参考资料

https://stackoverflow.com/questions/64769797/latin-1-codec-cant-encode-character-u2019

https://www.cnblogs.com/xtmp/p/12693862.html

