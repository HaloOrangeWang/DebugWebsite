我在第一次写Python爬虫的时候，没过多久Python就会报错，然后停止采集。总是没办法从头到尾把数据采集下来。每一下次报错我都要去找原因，随着一次又一次的报错问题越来越少。比如我要采集的标签里面没有URL，URL为空就会报错，或者页面没有URL也会报错。我非常的生气。于是我是用try....except语句跳过错误，但是还是遇到了问题。什么问题呢？就是try....except语句只能跳过一次错误，第二次错误就会失效。所以我想到了下面这种方法。

def mistaken():try:print('*****循环跳过，本页无内容*****')######采集代码########## print('——————————正常运行——————————')except:mistaken()

def main():z = 0while z <= 50000:try:######采集代码########## print('——————————正常运行——————————')except :mistaken()z += 1time.sleep(1)

通过在主要代码里加入自己创建的mistaken()函数(函数中重新启动采集代码)，然后在函数mistaken()中使用try……except语法再次调用mistaken()函数，就可以实现不管程序遇到什么问题都会继续采集下去了(即使没有数据采集了，也会继续采集下去)

